<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interview with Dr. Manjeet Rege</title>
    <link rel="stylesheet" href="styles.css">
</head>
<style>
    /* General Styles */
body {
    font-family: Arial, sans-serif;
    line-height: 1.6;
    margin: 0;
    padding: 0;
    background: #f4f4f9;
    color: #333;
}

/* Header Styles */
header {
    background: #009688;
    color: #fff;
    padding: 20px;
    text-align: center;
    animation: fadeIn 2s;
}

header h1 {
    margin: 0;
    font-size: 2.5em;
}

header p {
    margin: 0;
    font-size: 1.2em;
}

/* Main Section Styles */
main {
    padding: 20px;
    max-width: 1200px;
    margin: auto;
}

h2 {
    color: #009688;
    border-bottom: 2px solid #009688;
    padding-bottom: 10px;
    margin-bottom: 20px;
}

h3 {
    color: #00796b;
    margin-top: 20px;
}

/* Interview Section Styles */
.interview p {
    margin: 10px 0;
    text-align: justify;
    animation: slideIn 1s ease-out;
}

/* Interviewer Section Styles */
.interviewer {
    background: #00796b;
    color: #fff;
    padding: 20px;
    border-radius: 5px;
    animation: fadeIn 2s;
}

.interviewer h2 {
    margin: 0;
}

/* Footer Styles */
footer {
    background: #009688;
    color: #fff;
    text-align: center;
    padding: 10px;
    position: fixed;
    width: 100%;
    bottom: 0;
}

/* Animations */
@keyframes fadeIn {
    from {
        opacity: 0;
    }
    to {
        opacity: 1;
    }
}

@keyframes slideIn {
    from {
        transform: translateX(-100%);
        opacity: 0;
    }
    to {
        transform: translateX(0);
        opacity: 1;
    }
}

/* Responsive Styles */
@media (max-width: 768px) {
    header h1 {
        font-size: 2em;
    }

    header p {
        font-size: 1em;
    }

    .interviewer {
        padding: 10px;
    }
}

</style>
<body>
    <header>
        <h1>Dr. Manjeet Rege Of The University of St Thomas On The Future Of Artificial Intelligence</h1>
        <p>An Interview With David Leichner</p>
    </header>
    <main>
        <section class="interview">
            <h2>Introduction</h2>
            <p>People’s perception is that AI is perfect because it’s a computer, but that’s not the case. AI learns from people and people make mistakes. When the first AI model was deployed, it had limitations. Recognizing that it’s not perfect and will improve over time is important.</p>

            <h2>About Dr. Manjeet Rege</h2>
            <p>As part of our series about the future of Artificial Intelligence, I had the pleasure of interviewing Dr. Manjeet Rege. Dr. Manjeet Rege is Chair of the Department of Software Engineering and Data Science and Director of the Center for Applied Artificial Intelligence at the University of St. Thomas, one of the largest top data science programs in the United States. As a lifelong learner, he instills in his students a passion for pursuing knowledge about machine learning throughout their careers.</p>

            <h2>Interview</h2>
            <h3>Can you share with us the ‘backstory” of how you decided to pursue this career path in AI?</h3>
            <p>I focused on machine learning, which is part of AI, while studying for my Ph.D. in computer science. I needed an area of specialization as part of my doctorate program and I was assigned to a neurosurgery planning project that created medical images of brain scans. In fact, I had to attend a neurosurgery to observe the process. My task was to create a medical image database and when that was created, the next task was figuring out how to retrieve that information from the database. When you have to work with multimedia data, the traditional query mechanisms don’t work. It takes machine learning to make sense of image data and that’s how I was drawn to machine learning.</p>

            <h3>What lessons can others learn from your story?</h3>
            <p>You don’t need to necessarily pick one field and stick with it throughout your education and career. I received my bachelor’s degree in mathematics. For my master’s degree, I went to business school to study information systems. I chose computer science for my Ph.D. and then opted for machine learning within computer science. Sometimes people have a very traditional path where you receive all your degrees in the same field. Ultimately, it’s about adapting to a new subject and a new topic. As long as you’re a lifelong learner, you can make it in the particular field that you’ve chosen.</p>

            <h3>Can you tell our readers about the most interesting projects you are working on now?</h3>
            <p>I like to apply AI to different problems because ultimately, it’s about solving real-world problems. I recently worked on a credit risk analysis problem where I tried to predict whether a person would be a risk on a lease based on their financial history with a company. I’ve also worked on microexpression detection. Microexpressions are subtle expressions people have that can’t be seen by the human eye, but an AI model can observe the video so closely that it can tell you there was a subtle change.</p>

            <h3>None of us are able to achieve success without some help along the way. Is there a particular person who you are grateful towards who helped get you to where you are? Can you share a story about that?</h3>
            <p>I’ve benefited from great teachers along the way. To me, if I came across a great teacher in the pursuit of knowledge, it never mattered what course they were teaching because I was interested in receiving the professor’s knowledge. Ultimately, education is about a partnership between teachers and students, and you sync up well with certain professors.</p>
            <p>On a personal level, I wouldn’t be where I am without the support of my wife. I was just starting my Ph.D. when we met. She supported me during my studies and has continued to support me in my pursuits since then. She has been an equal partner.</p>

            <h3>What are the 5 things that most excite you about the AI industry? Why?</h3>
            <p>I’m excited that AI is now accessible to a wide variety of people. About 15 years ago, AI was mostly accessible to Ph.D. students and AI researchers. It’s now accessible to everyone from software engineers to high school students. You don’t need to have a deep level of understanding of AI to be able to do a lot with it.</p>
            <p>That brings me to the second exciting aspect: the opportunity to apply AI to other things. Just look at the number of applications for AI that have come up recently. Twenty years ago, we thought about self-driving cars in sci-fi movies. Now that’s a reality.</p>
            <p>The assistance AI can provide for recommendations is also huge. Without recommendations, it would be a nightmare to find a particular movie on Netflix. Recommendation systems have been the most revenue-generating application of machine learning out there.</p>
            <p>Conversational AI, such as Alexa or Google Home, is really helping people build a dialogue. Older people like to tell stories from their past, but many times younger generations don’t have time to listen. But there are AI applications that can talk with them and help reduce cognitive decline. When AI is helping humanity in that way, it’s very satisfying to see that as an AI practitioner.</p>

            <h3>What are the 5 things that concern you about the AI industry? Why?</h3>
            <p>I think responsible and ethical use of AI is a broader issue. AI has a lot of promise as long as it’s used to benefit humanity. If it gets into the wrong hands, it can have a negative impact.</p>
            <p>People’s perception is that AI is perfect because it’s a computer, but that’s not the case. AI learns from people and people make mistakes. When the first AI model was deployed, it had limitations. Recognizing that it’s not perfect and will improve over time is important.</p>
            <p>When we think of the limitations of AI, we shouldn’t think that AI can’t be fooled. There are times when AI can be fooled very easily. For example, a human driver wouldn’t be bothered by small stickers on a stop sign, but an AI camera wouldn’t notice the stop sign and the car wouldn’t stop. That’s a limitation.</p>
            <p>There’s also bias in AI because it’s learning from data. When you don’t have equal representation of different gender and racial backgrounds, AI develops an affinity for the most frequently used words in terms of race and gender. For instance, if it’s used in HR, AI could develop a bias toward male job applicants if there are more male applicants. We’re not near perfection with AI, but it’s a work in progress.</p>

            <h3>As you know, there is an ongoing debate between prominent scientists, (personified as a debate between Elon Musk and Mark Zuckerberg,) about whether advanced AI has the future potential to pose a danger to humanity. What is your position about this?</h3>
            <p>I am concerned about the negative impact AI can have in the wrong hands. Take for instance a video of a celebrity or politician saying something or doing something. The issue of deep fakes can prompt two different situations. The celebrity or politician may have done it, but then claim that it’s a deep fake. On the other hand, it could be a deep fake and released on social media, causing immediate reactions that turn the tide against a politician.</p>

            <h3>What can be done to prevent such concerns from materializing? And what can be done to assure the public that there is nothing to be concerned about?</h3>
            <p>Detecting what is real and what is AI-generated, such as a deep fake video or ChatGPT text, is an active area of research. Particularly when it comes to bias-related issues in AI, we have to recognize that it won’t be perfect once it’s developed. The goal of AI is to improve our productivity. AI is by humans and for humans to ultimately enhance our productivity. AI goes through multiple iterations based on human feedback and there are ways of minimizing bias.</p>

            <h3>How have you used your success to bring goodness to the world? Can you share a story?</h3>
            <p>One of my goals is to make AI accessible to a broader audience as much as possible. I’ve been to Africa several times as part of a federal grant one of our former students at the University of St. Thomas received to develop a data science capacity in Ivory Coast. I traveled there to train and develop data scientists there. I loved the experience because I can see the wider impact of what we’re doing.</p>
            <p>I also spend time talking with K-12 students about introductory AI and programmed language. It’s important to instill interest at a young age, by making AI more interesting and fun. At the elementary school level, we can talk about AI applications and their Xbox games. I do whatever I can to build awareness about AI.</p>

            <h3>As you know, there are not that many women in your industry. Can you advise what is needed to engage more women into the AI industry?</h3>
            <p>At the University of St. Thomas, a third of the students in our software and data science graduate programs are women. We take pride that we shape female leaders and many of our female graduates are at the senior level in the IT industry. There are a number of conferences organized specifically for women in the industry, which provide a great learning opportunity for women. The more we can promote these kinds of events and encourage women to advance their careers, the better.</p>

            <h3>What is your favorite “Life Lesson Quote”? Can you share a story of how that had relevance to your own life?</h3>
            <p>My life lesson quote is from Mahatma Gandhi: “Live as if you were to die tomorrow. Learn as if you were to live forever.” I find this quote relevant because lifelong learning is no longer an option, it’s a necessity. It’s important to continuously adapt and embrace emerging technologies to stay current and relevant in the workplace today. In our graduate programs in software and data science at the University of St. Thomas, many of our students are changing careers, and they realize the importance of investing in their education for their professional growth. All of our educational offerings, no matter how technical and complex, are taught in an applied manner to help non-traditional students achieve their academic goals.</p>

            <h3>You are a person of great influence. If you could start a movement that would bring the most amount of good to the most amount of people, what would that be? You never know what your idea can trigger. :-)</h3>
            <p>Our goal at the University of St. Thomas is to teach our students to have a moral compass and to change the world for the better after they leave our campus. My movement would focus on the responsible use of AI and advancing the common good.</p>

            <h3>How can our readers further follow your work online?</h3>
            <p>I am very active on LinkedIn and often speak in the media. I also host a podcast called “All Things Data” that people can follow.</p>
        </section>

        <section class="interviewer">
            <h2>About The Interviewer</h2>
            <p>David Leichner is a veteran of the Israeli high-tech industry with significant experience in the areas of cyber and security, enterprise software and communications. At Cybellum, a leading provider of Product Security Lifecycle Management, David is responsible for creating and executing the marketing strategy and managing the global marketing team that forms the foundation for Cybellum’s product and market penetration. Prior to Cybellum, David was CMO at SQream and VP Sales and Marketing at endpoint protection vendor, Cynet. David is a member of the Board of Trustees of the Jerusalem Technology College. He holds a BA in Information Systems Management and an MBA in International Business from the City University of New York.</p>
        </section>
    </main>
</body>
</html>
